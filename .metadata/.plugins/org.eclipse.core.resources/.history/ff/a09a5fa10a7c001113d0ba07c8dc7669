
import nltk
from nltk.corpus import movie_reviews
from string import punctuation

class Classificador():
    
    def __init__(self, training_set=None):
        if training_set:
            self.training_set = self.__change_format(training_set)
           
        
        else:  
            negids = movie_reviews.fileids('neg')
            posids = movie_reviews.fileids('pos')             
            negfeats = [(self.__change_format2(movie_reviews.words(fileids=[f]), 'neg')) for f in negids]
            posfeats = [(self.__change_format2(movie_reviews.words(fileids=[f]), 'pos')) for f in posids]
            
            self.training_set = negfeats + posfeats
            
        self.word_features = self.__get_word_features(self.__get_words_in_training_set())
            
        self.training_set = nltk.classify.apply_features(self.__extract_features, self.training_set)
        print 'aqui'
        self.classifier = nltk.NaiveBayesClassifier.train(self.training_set)
    
    def __word_feats(self, words):
        return dict([(word, True) for word in words])
    
    def __change_format(self, lista):
        tweets = []
        for (words, sentiment) in lista:
            words_filtered = [e.lower() for e in words.split() if len(e) >= 3]
            tweets.append((words_filtered, sentiment))
            
        return tweets
    
    def __change_format2(self, lista, sentimento):
        words_filtered = []
        for word in lista:
            if len(word) >= 3:
                word = word.lower()
                words_filtered.append(word)
            
        return (words_filtered, sentimento)
    
    def __get_words_in_training_set(self):
        all_words = []
        for (words, sentiment) in self.training_set:
            all_words.extend(words)
          
        return all_words
    
    def __get_word_features(self, wordlist):
        wordlist = nltk.FreqDist(wordlist)
        word_features = wordlist.keys()
        
        return word_features
    
    def __extract_features(self, document):
        document_words = set(document)
        features = {}
        
        for word in self.word_features:
            features['contains(%s)' % word] = (word in document_words)
          
        return features
    
    def analisar(self, text):
        return self.classifier.classify(self.__extract_features(text.split()))

    def precisao(self, testfeats):
        
        testfeats = self.__change_format(testfeats) 
        testfeats = [ (dict([(word, True) for word in t[0]]), t[1]) for t in testfeats]
        
        return nltk.classify.util.accuracy(self.classifier, testfeats)
    
    
    """
        Apenas para testes!
    """
        
if __name__ == '__main__':
    
    pos_tweets = [('I love this car', 'positive'),
              ('This view is amazing', 'positive'),
              ('I feel great this morning', 'positive'),
              ('I am so excited about the concert', 'positive'),
              ('He is my best friend', 'positive')]

    neg_tweets = [('I do not like this car', 'negative'),
              ('This view is horrible', 'negative'),
              ('I feel tired this morning', 'negative'),
              ('I am not looking forward to the concert', 'negative'),
              ('He is my enemy', 'negative')]

    test_tweets = [
               ('I feel happy this morning', 'positive'),
               ('Larry is my friend', 'positive'),
               ('I do not like that man', 'negative'),
               ('My house is not great', 'negative'),
               ('Your song is annoying', 'positive')
               ]
    
    
#    cl = Classificador(pos_tweets + neg_tweets)
    cl = Classificador(None)

    for t in test_tweets:
        print (cl.analisar(t[0]) == t[1])
        
#    print cl.classifier.show_most_informative_features()
#    print 'accuracy:', cl.precisao(test_tweets)

    
